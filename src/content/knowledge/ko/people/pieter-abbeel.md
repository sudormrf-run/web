---
title: Pieter Abbeel
description: UC Berkeley 교수, Covariant 창업자, 로봇 강화학습 선구자
tags: [pieter-abbeel, berkeley, covariant, reinforcement-learning, robotics]
category: people

# Authorship
createdBy:
  name: 박종현
  email: jhpark@sudormrf.run
lastEditedBy:
  name: 박종현
  email: jhpark@sudormrf.run
lastEditedAt: 2026-01-15
---

# Pieter Abbeel

> Home > People > Pieter Abbeel

---

## Profile

| 항목 | 내용 |
|------|------|
| 현직 | UC Berkeley 교수 |
| 회사 | Covariant 공동창업자 & Chief Scientist |
| 이전 | OpenAI 연구 과학자 (2016-2017) |
| PhD | Stanford University (Advisor: Andrew Ng) |
| 국적 | 벨기에 |

---

## 핵심 기여

- **로봇 강화학습 선구자**: 실제 로봇에서 동작하는 RL 연구의 초기 개척자
- **Inverse Reinforcement Learning**: 시연에서 보상 함수 학습
- **Covariant 창업**: AI 기반 로봇 피킹 회사, $2B+ 가치
- **OpenAI 초기 멤버**: 초기 로봇 연구 주도
- **다수의 영향력 있는 제자 배출**: Chelsea Finn, Sergey Levine 등

---

## Research Timeline

### PhD & Early Career (2004-2010)

**Stanford - Andrew Ng 지도**

| Year | Work | Impact |
|------|------|--------|
| 2004 | Apprenticeship Learning via IRL | Inverse RL 초기 연구 |
| 2007 | Autonomous Helicopter Flight | 실제 로봇 RL 시연 |
| 2008 | UC Berkeley 교수 부임 | BAIR 설립 참여 |

### UC Berkeley Professor (2008-present)

**BAIR (Berkeley AI Research) 핵심 멤버**

| Year | Work | Impact |
|------|------|--------|
| 2010 | Learning from Demonstrations | 시연 기반 학습 정립 |
| 2013 | Deep RL for Robotics | 딥러닝 + 로봇 RL |
| 2015 | TRPO | Policy gradient 안정화 |
| 2016 | Benchmarking Deep RL | RL 벤치마크 정립 |

### OpenAI (2016-2017)

**OpenAI 초기 로봇 연구**

| Year | Work | Impact |
|------|------|--------|
| 2016 | OpenAI Gym | RL 표준 환경 |
| 2017 | One-Shot Imitation Learning | Few-shot 로봇 학습 |
| 2017 | Domain Randomization | Sim-to-Real 핵심 기법 |

### Covariant (2017-present)

**AI 로봇 피킹 회사 창업**

| Year | Work | Impact |
|------|------|--------|
| 2017 | Covariant 창업 | AI 기반 물류 로봇 |
| 2020 | Covariant Brain | 범용 로봇 AI 플랫폼 |
| 2023 | RFM-1 | Robotics Foundation Model |
| 2024 | $2B+ 가치 평가 | 로봇 AI 스타트업 선두 |

---

## Major Publications

### Inverse Reinforcement Learning
- **Apprenticeship Learning via IRL** (ICML 2004) - IRL 초기 연구
- Maximum Entropy IRL (AAAI 2008)

### Deep Reinforcement Learning
- **TRPO** (Trust Region Policy Optimization, 2015)
- **GAE** (Generalized Advantage Estimation, 2016)
- Benchmarking Deep RL (2016)

### Robotics
- Autonomous Helicopter Aerobatics (2010)
- Learning Dexterous Manipulation (2018)
- Domain Randomization for Sim-to-Real (2017)

---

## Key Ideas

### Inverse Reinforcement Learning (2004)
```
핵심: 전문가 시연에서 보상 함수 R을 학습

기존 RL: R → π (보상 → 정책)
IRL: π* → R (전문가 정책 → 보상 추론)
```

**영향:**
- 로봇이 "왜" 그렇게 행동하는지 학습
- Imitation learning의 이론적 기반

### Domain Randomization (2017)
```
핵심: 시뮬레이션에서 물리/시각 파라미터를 랜덤하게 변화시켜 학습

시뮬레이션 (다양한 조건) → 실제 로봇 (zero-shot transfer)
```

**영향:**
- Sim-to-Real의 핵심 기법
- 현재 대부분의 로봇 시뮬레이션 학습에서 사용

---

## Covariant & RFM-1

### Covariant (2017-)
- **미션**: 범용 로봇 AI
- **제품**: AI 기반 물류 피킹 로봇
- **고객**: DHL, ABB, Knapp 등
- **가치**: $2B+ (2024)

### RFM-1 (2023)
- **Robotics Foundation Model**
- 다양한 물체, 환경에서 일반화
- 실제 물류 환경 배포

---

## Philosophy & Direction

### 연구 철학
> "로봇이 인간처럼 학습하려면, 인간이 배우는 방식을 이해해야 한다"

### 연구 방향 변화
1. **2004-2010**: Inverse RL, learning from demonstrations
2. **2010-2015**: Deep RL fundamentals
3. **2015-2017**: Policy optimization (TRPO, GAE)
4. **2017-현재**: 실용적 로봇 AI, foundation models

---

## Students & Mentees

Pieter Abbeel 연구실 출신/협력:
- **Chelsea Finn** (Stanford 교수)
- **Sergey Levine** (UC Berkeley 교수)
- **Rocky Duan** (Covariant)
- **John Schulman** (OpenAI, PPO 개발자)
- 다수의 RL/로봇 연구자

---

## Awards & Recognition

- ACM Prize in Computing (2021)
- IEEE RAS Early Career Award
- IJCAI Computers and Thought Award
- Sloan Research Fellowship
- TR35 (MIT Technology Review 35 Under 35)

---

## Links

- [UC Berkeley Profile](https://people.eecs.berkeley.edu/~pabbeel/)
- [Covariant](https://covariant.ai/)
- [Google Scholar](https://scholar.google.com/citations?user=vtwH6GkAAAAJ)
- [Twitter/X](https://twitter.com/paborisov)

---

## See Also

- [Chelsea Finn](chelsea-finn.md)
- [Sergey Levine](sergey-levine.md)
- [Covariant](../companies/covariant.md)
