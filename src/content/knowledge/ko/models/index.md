---
title: VLA 모델 목록
description: Vision-Language-Action 모델들의 역사와 현황
category: models
order: 1
isFeatured: true
icon: brain
---

# VLA 모델 목록

> Vision-Language-Action 모델들의 역사와 목록

VLA(Vision-Language-Action) 모델은 시각 정보와 언어 지시를 받아 로봇 동작을 출력하는 AI 모델입니다.

---

## 주요 모델

| 모델 | 핵심 의의 |
|------|----------|
| RT-1/2 | VLA의 시초, "Action as Language" 패러다임 정립 |
| OpenVLA | 최초 대규모 오픈소스 VLA, 연구 민주화 |
| π Series | Flow Matching, Open-world 일반화, RL 자가 개선 |
| SmolVLA | 450M으로 π0 수준, MacBook 실행 가능 |
| GR00T | 최초 오픈 휴머노이드 파운데이션, 합성 데이터 입증 |

---

## 타임라인

2022년 RT-1을 시작으로 VLA 모델은 빠르게 발전해왔습니다.

- 2022: RT-1 (Google)
- 2023: RT-2, ACT, Diffusion Policy
- 2024: Octo, OpenVLA, GR00T, π0
- 2025: SmolVLA, Gemini Robotics, π0.5
