---
title: π0.5 (pi-zero-point-five)
description: Physical Intelligence의 Open-World Generalization VLA
tags: [pi0-5, physical-intelligence, open-world, generalization, vla, web-data]
category: models
---

# π0.5 (pi-zero-point-five)

> Home > Models > [π Series](pi-series.md) > π0.5

---

## 핵심 의의

- **Open-World 일반화**: 학습하지 않은 완전히 새로운 가정에서도 작동 - 로봇 일반화의 새로운 기준
- **Web 데이터 Co-training**: 이미지 캡셔닝, Visual QA, 객체 탐지 등 웹 데이터와 로봇 데이터 동시 학습
- **Knowledge Insulation**: VLM 지식을 보존하면서 로봇 학습 - 7.5배 적은 학습 스텝
- **Dual-Pathway 추론**: 고수준 의미 액션 + 저수준 모터 명령을 동일 모델에서 생성
- **실제 가정 검증**: 샌프란시스코 3개 렌탈 주택에서 주방/침실 정리 태스크 수행
- **Scaling Law 발견**: ~100개 학습 환경 후 성능이 포화 - 실용적 데이터 요구량 제시

![π0.5 Architecture](../assets/models/pi0/pi0.5.png)
<p align="center"><em>π0.5: Open-world 일반화를 위한 Co-training 아키텍처</em></p>

---

## Overview

π0.5는 Physical Intelligence가 2025년 4월 발표한 open-world generalization VLA입니다. 기존 VLA들이 학습 환경과 유사한 곳에서만 작동하는 한계를 극복하고, 완전히 새로운 환경에서도 의미 있는 성능을 보여줍니다.

| 항목 | 내용 |
|------|------|
| 발표 | 2025년 4월 22일 |
| 회사 | Physical Intelligence |
| 블로그 | [pi.website/blog/pi05](https://www.pi.website/blog/pi05) |
| 기반 | π0 |

---

## Key Innovation: Open-World Generalization

### 기존 VLA의 한계

| 기존 VLA | π0.5 |
|---------|------|
| 학습 환경과 유사한 곳에서만 작동 | **완전히 새로운 환경에서도 작동** |
| 실험실 수준 | **실제 가정 수준** |
| 특정 물체에 특화 | **처음 보는 물체도 처리** |

### 검증

- **장소**: 샌프란시스코 3개 렌탈 주택
- **조건**: 학습 데이터에 전혀 없는 새로운 환경
- **태스크**: 주방 정리, 침실 정리, 식기 세척 등

---

## Architecture

### Co-training Strategy

π0.5는 다양한 데이터 소스를 동시에 학습:

```
┌─────────────────────────────────────────────────────────────┐
│                 π0.5 Co-training Architecture                │
├─────────────────────────────────────────────────────────────┤
│                                                              │
│   ┌──────────┐  ┌──────────┐  ┌──────────┐  ┌──────────┐   │
│   │ Web Data │  │ Language │  │ Subtask  │  │  Robot   │   │
│   │ (VQA,    │  │  Demo    │  │ Commands │  │  Action  │   │
│   │ Caption) │  │          │  │          │  │          │   │
│   └────┬─────┘  └────┬─────┘  └────┬─────┘  └────┬─────┘   │
│        │             │             │             │          │
│        └─────────────┴─────────────┴─────────────┘          │
│                           │                                  │
│                           ▼                                  │
│         ┌─────────────────────────────────────┐             │
│         │           VLM Backbone (3B)         │             │
│         │      (Gradient Blocked for KI)      │             │
│         └─────────────────┬───────────────────┘             │
│                           │                                  │
│           ┌───────────────┼───────────────┐                 │
│           ▼               ▼               ▼                 │
│   ┌──────────────┐ ┌──────────────┐ ┌──────────────┐       │
│   │ Discrete     │ │ Continuous   │ │ Language     │       │
│   │ Action Token │ │ Flow Action  │ │ Output       │       │
│   │ (FAST)       │ │ (Motor Cmd)  │ │              │       │
│   └──────────────┘ └──────────────┘ └──────────────┘       │
│                                                              │
└─────────────────────────────────────────────────────────────┘
```

### 데이터 유형별 역할

| 데이터 유형 | 역할 |
|------------|------|
| **Web 데이터** | 이미지 캡셔닝, Visual QA, 객체 탐지 → 시각 이해 |
| **언어 시연** | 단계별 지시 학습 → 언어 지시 따르기 |
| **서브태스크 명령** | 고수준 의미 레이블 → 계층적 이해 |
| **로봇 액션** | 다중 embodiment → 물리적 제어 |

### Knowledge Insulation (KI)

VLM 지식을 보존하면서 로봇 학습:

| 문제 | 해결책 |
|------|--------|
| Action Expert → VLM 역전파 | **Gradient Blocking** |
| 로봇 학습이 언어 이해 손상 | **Discrete Action 동시 학습** |

**결과:**
- 7.5배 적은 학습 스텝
- 언어 지시 준수율 향상
- 시각적 이해 능력 보존

---

## Dual-Pathway Inference

π0.5는 동일 모델에서 두 가지 수준의 출력 생성:

### High-Level (Semantic)

```
관측 → VLM → "베개를 집어" (discrete token)
```

- 의미적 액션 생성
- 이산 토큰 디코딩

### Low-Level (Motor)

```
관측 + 의미 액션 → Flow Matching → 50-step 모터 명령 (1초)
```

- 50Hz 연속 제어
- Flow matching 기반

### Chain-of-Thought 효과

```
"침실 정리해줘"
    ↓
"베개를 집어" → [모터 명령]
    ↓
"이불을 펴" → [모터 명령]
    ↓
...
```

---

## Training Data Ablation

### 데이터 유형별 효과

| 데이터 | 효과 |
|--------|------|
| **Web 데이터** | OOD 객체 인식에서 가장 큰 효과 |
| **Cross-Embodiment (CE)** | ~17-18% 성능 향상 |
| **Multiple Environment (ME)** | ~33-66% 성능 향상 |

### Scaling Study

| 학습 환경 수 | 성능 |
|-------------|------|
| 10개 | 기준선 |
| 50개 | 상당한 향상 |
| **~100개** | **성능 포화** |

**인사이트**: ~100개 환경 후 테스트 환경에서 직접 학습한 것과 유사한 성능

---

## Performance

### Open-World 태스크

| 환경 | 태스크 | 성능 |
|------|--------|------|
| 새 주방 | 식기 세척기에 넣기 | 수행 가능 |
| 새 침실 | 베드 메이킹 | 수행 가능 |
| 새 거실 | 물체 정리 | 수행 가능 |

### 특징

- **반응형 정책**: 환경 변화와 인간 간섭에 대응
- **언어 유연성**: "접시를 싱크대에" ~ "그릇들 치워"
- **객체 일반화**: 처음 보는 물체도 카테고리 수준 이해

### 한계

- 완벽하지 않은 실행 (실패 발생)
- 복잡한 시퀀스에서 오류 누적
- 정밀 조작에서 어려움

---

## Model Variants

| 모델 | 설명 |
|------|------|
| **pi05-base** | 기본 사전학습 모델 |
| **pi05-droid** | DROID 데이터 특화 |
| **pi05-libero** | LIBERO 시뮬레이션 특화 |

---

## Comparison with π0

| 항목 | π0 | π0.5 |
|------|-----|------|
| 일반화 | 학습 환경 내 | **새로운 환경** |
| 학습 데이터 | 로봇 데이터 위주 | **Web + 로봇** |
| Knowledge Insulation | 없음 | **적용** |
| 학습 효율 | 기준 | **7.5x 향상** |

---

## Real-World Testing

### 테스트 환경

- **위치**: 샌프란시스코
- **유형**: 3개 렌탈 주택
- **조건**: 학습 데이터에 전혀 없음

### 수행 태스크

| 태스크 | 복잡도 |
|--------|--------|
| 주방 정리 | 다중 물체, 다중 위치 |
| 침실 정리 | 베드 메이킹, 베개 배치 |
| 식기 세척 | 싱크대 → 식기세척기 |

### 관찰 결과

> "사람이 새로운 도전에 접근하는 유연함과 자원 활용의 힌트를 보여줌"

- 완벽하지는 않지만 의미 있는 진전
- 기존 VLA로는 불가능했던 수준

---

## Technical Details

### Model Specifications

| 구성 요소 | 사양 |
|----------|------|
| VLM Backbone | 3B |
| Action Expert | 300M |
| 총 파라미터 | ~3.3B |
| 제어 주파수 | 50Hz |

### Training

| 항목 | 내용 |
|------|------|
| 기반 | π0 체크포인트 |
| 추가 | Web 데이터 co-training |
| 기법 | Knowledge Insulation |

---

## References

- [Physical Intelligence Blog - π0.5](https://www.pi.website/blog/pi05)
- [Knowledge Insulation Research](https://www.pi.website/research/knowledge_insulation)

---

## See Also

- [π Series](pi-series.md)
- [π0](pi0.md)
- [π*0.6](pi0-6-star.md)
- [Physical Intelligence](../companies/physical-intelligence.md)

### 관련 인물
- [Karol Hausman](../people/karol-hausman.md) - Physical Intelligence 공동창업자
- [Chelsea Finn](../people/chelsea-finn.md) - Physical Intelligence 공동창업자
- [Sergey Levine](../people/sergey-levine.md) - Physical Intelligence 공동창업자
- [Pete Florence](../people/pete-florence.md) - Physical Intelligence 공동창업자

